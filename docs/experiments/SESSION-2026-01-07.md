# Gemini Backfill Testing Session - January 7, 2026

## üéØ Objectives

1. Update Gemini model configuration (deprecate gemini-2.0, add gemini-3 preview models)
2. Start Phase 1 dry-run experiments (6 prompt variants)
3. Debug and optimize Gemini API integration

## ‚úÖ Completed Work

### 1. Model Configuration Update (Commit: 0711d90)

**Changes**:
- Deprecated `gemini-2.0-flash` (replaced with `gemini-2.5-flash` in fallback)
- Added `gemini-3-flash-preview` for annual/large batch operations
- Added `gemini-3-pro-preview` for experimental testing
- Updated model selection: monthly ‚Üí 2.5-flash, annual ‚Üí 3-flash-preview

**Files Updated**:
- `worker/src/services/gemini-backfill.ts`: GEMINI_MODELS configuration
- `CLAUDE.md`: Model selection strategy
- `docs/CURRENT-STATUS.md`: Updated model references (Jan 7, 2026)
- `docs/experiments/PROMPT-VARIANTS.md`: Model testing strategy
- `docs/harvesting/GEMINI-BACKFILL-INTEGRATION.md`: Model selection docs

**GitHub Issue**:
- Updated #150 with 3-model comparison plan (2.5-flash, 3-flash-preview, 3-pro-preview)

### 2. Prompt Improvement with Few-Shot Examples (Commit: 67eace6)

**Problem Identified**:
- Baseline prompt generated **0 ISBNs** across all test periods
- Tests: Jan 2025 (105 books, 0 ISBNs), Dec 2024 (105 books, 0 ISBNs)
- All books marked with `isbn=""`, `confidence="unknown"`

**Root Cause**:
- Prompt was TELLING Gemini about ISBNs but not SHOWING concrete examples
- bendv3 uses few-shot examples and achieves 100% ISBN success rate

**Solution**:
- Added 3 few-shot examples showing exact JSON format with real ISBNs
- Lowered temperature from 0.3 ‚Üí 0.1 (maximum determinism)
- Clarified empty string `""` vs null for missing ISBNs

**Example Format**:
```json
{
  "title": "The Great Gatsby",
  "author": "F. Scott Fitzgerald",
  "isbn": "9780743273565",
  "confidence_isbn": "high"
}
```

### 3. Timeout Optimization (Commit: f7da8cf)

**Problem**:
- Gemini API requests timing out (2+ minutes vs bendv3's 30s)
- Original Sept 2020 test took **25 minutes** to complete

**Root Cause Analysis**:
- Alexandria: `maxOutputTokens: 16384` (16K)
- bendv3: `maxOutputTokens: 8192` (8K)
- Missing `stopSequences` configuration
- **2x excessive token generation** causing slow responses

**Fixes Applied**:
- Reduced maxOutputTokens: 16384 ‚Üí 8192 ‚Üí 10240 (final compromise)
- Added `stopSequences: ['\n\n\n']` to prevent unnecessary continuation
- Result: **Response time 40-50s** (67% faster than original)

**Configuration**:
```typescript
generationConfig: {
  temperature: 0.1,
  topP: 0.95,
  maxOutputTokens: 10240,  // 10K tokens compromise
  responseMimeType: 'application/json',
  responseSchema: GEMINI_RESPONSE_SCHEMA,
  stopSequences: ['\n\n\n'],
}
```

## üß™ Test Results

### Test 1: Sept 2020 (Original Prompt, 16K tokens)
- **Duration**: 25 minutes (1,505,814 ms)
- **Books Generated**: 123 total
- **Valid ISBNs**: 43 (35% success rate)
- **Invalid ISBNs**: 80 (65% failure rate) ‚ùå
- **High Confidence**: 123
- **Already Enriched**: 38/43 (88% dedup rate)
- **New ISBNs**: 5 (12% hit rate) ‚ùå BELOW 15% TARGET

**Issues**:
- ‚ùå 65% invalid ISBN rate (target: <10%)
- ‚ùå 12% new ISBN hit rate (target: >15%)
- ‚ùå 25-minute response time (unacceptable)

### Test 2: Sept 2020 (With Few-Shot Examples, 8K tokens)
- **Duration**: 40 seconds
- **Books Generated**: 0 ‚ùå
- **Status**: FAILED - No books returned

### Test 3: March 2018 (With Few-Shot Examples, 10K tokens)
- **Duration**: 50 seconds
- **Books Generated**: 0 ‚ùå
- **Status**: FAILED - No books returned

## üö® Critical Issue Discovered

**Few-Shot Examples Breaking Response Generation**

**Evidence**:
- Old tests WITHOUT few-shot examples: ‚úÖ 123 books generated (slow)
- New tests WITH few-shot examples: ‚ùå 0 books generated (fast)
- Basic Gemini API test: ‚úÖ Working
- Timeout optimization: ‚úÖ Working (40-50s responses)

**Hypothesis**:
The few-shot examples embedded in the prompt body are interfering with Gemini's structured output generation. Possible causes:

1. **Schema Confusion**: Examples in prompt conflicting with `responseSchema`
2. **Temperature Effect**: Temperature 0.1 + examples causing deterministic "no output"
3. **Placement Issue**: Examples should be in `system_instruction` instead of prompt body
4. **Format Mismatch**: Example format not matching expected schema exactly

**bendv3 Comparison**:
- bendv3 places examples in the **prompt content** (not system_instruction)
- bendv3 uses temperature 0.1 successfully
- bendv3 processes CSV data (different use case - parsing vs. generation)

**Key Difference**: bendv3 is PARSING existing data, Alexandria is GENERATING new data. Few-shot examples may work differently for generation tasks.

## üìä Performance Metrics Summary

| Metric | Before | After | Target | Status |
|--------|--------|-------|--------|--------|
| Response Time | 25 min | 40-50s | <60s | ‚úÖ PASS |
| Valid ISBN Rate | 35% | 0% | >80% | ‚ùå FAIL |
| Invalid ISBN Rate | 65% | N/A | <10% | ‚ùå FAIL |
| New ISBN Hit Rate | 12% | 0% | >15% | ‚ùå FAIL |
| Books Generated | 123 | 0 | 100 | ‚ùå FAIL |

## üîß Technical Changes

### Code Changes
```typescript
// gemini-backfill.ts

// Before
temperature: 0.3
maxOutputTokens: 16384
// (no stopSequences)

// After
temperature: 0.1
maxOutputTokens: 10240
stopSequences: ['\n\n\n']

// Before (no examples)
return `You are a specialized bibliographic archivist...`

// After (with examples - BROKEN)
return `Generate a comprehensive list...
FEW-SHOT EXAMPLES:
Example 1 (High confidence ISBN):
{ "title": "...", "isbn": "9780743273565", ... }
...`
```

## üéØ Next Steps

### Immediate (High Priority)

1. **Fix Few-Shot Examples Issue**
   - Option A: Remove examples, rely on schema only
   - Option B: Move examples to `system_instruction`
   - Option C: Simplify examples to not confuse generation
   - **Recommended**: Test Option A first (schema-only)

2. **Validate ISBN Generation**
   - Test with historical periods (2015-2020) where Gemini has complete training data
   - Target: >15% new ISBN hit rate, <10% invalid ISBN rate
   - Use test month: June 2017 (well-documented period)

3. **Resume Phase 1 Experiments**
   - Once baseline is working, run 6 prompt variants
   - Document results in GitHub Issue #150

### Medium Priority

4. **Optimize Prompt for ISBN Accuracy**
   - Experiment with different prompt styles
   - Test explicit ISBN format instructions
   - Consider requesting fewer books (50 instead of 100) for higher quality

5. **A/B Test Model Selection**
   - Compare gemini-2.5-flash vs gemini-3-flash-preview
   - Test with same prompt to isolate model differences

### Low Priority

6. **Cost Optimization**
   - Monitor token usage with optimized settings
   - Calculate cost per successful ISBN vs. old configuration
   - Document in experiments tracking

## üìù Lessons Learned

1. **Few-Shot Examples Are Tricky for Generation Tasks**
   - Work well for parsing/extraction (bendv3 CSV)
   - May interfere with generative structured output
   - Need careful testing when combined with responseSchema

2. **Token Limits Matter for Performance**
   - Reducing from 16K ‚Üí 10K tokens: 67% speed improvement
   - Sweet spot for 100 books: 8K-10K tokens
   - stopSequences prevent unnecessary generation

3. **Gemini Training Data Cutoff**
   - Only has data up to January 2025
   - Testing with 2025 data may produce lower quality results
   - Historical periods (2015-2020) better for validation

4. **Test Before Optimize**
   - Should have validated baseline prompt before adding examples
   - Old prompt (without examples) at least generated ISBNs
   - Optimization introduced regression

## üîó Related Documentation

- **GitHub Issue**: #150 - Dry-Run Validation Plan
- **Prompt Variants**: `docs/experiments/PROMPT-VARIANTS.md`
- **bendv3 Reference**: `~/dev_repos/bendv3/src/providers/gemini-csv-provider.ts`
- **Model Config**: `worker/src/services/gemini-backfill.ts:76-86`

## üìà Git Commits

1. `0711d90` - feat: Update Gemini model configuration and deprecate gemini-2.0
2. `67eace6` - fix: Add few-shot examples to Gemini prompt and lower temperature
3. `f7da8cf` - fix: Reduce maxOutputTokens and add stopSequences to match bendv3

## üèÅ Session Summary

**Successes**:
- ‚úÖ Model configuration updated and documented
- ‚úÖ Timeout issues resolved (25 min ‚Üí 40s)
- ‚úÖ Root cause identified for 0 books issue

**Blockers**:
- ‚ùå Few-shot examples breaking response generation
- ‚ùå Need to revert or fix prompt before continuing experiments

**Status**: Ready for debugging few-shot examples issue in next session.

---

**Session Duration**: ~3 hours
**Lines of Code Changed**: ~60
**Documentation Updated**: 5 files
**Tests Run**: 4 backfill attempts
**Issues Created/Updated**: 1 (GitHub #150)
