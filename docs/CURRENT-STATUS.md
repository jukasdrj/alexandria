# Alexandria Current Status & Open Issues

**Last Updated:** January 5, 2026

## üéØ Active Issues

### P1 - HIGH Priority
1. **#114** - Author normalization database migration (awaiting direct DB connection)

### P2 - MEDIUM Priority
2. **#118** - Auto-healing/recovery system for bulk author harvesting

### P3 - LOW Priority (Future Enhancements)
3. **#117** - Semantic search with Cloudflare Vectorize
4. **#116** - Search analytics tracking with Analytics Engine
5. **#113** - Wikipedia + LLM fallback for authors without Wikidata
6. **#100** - GitHub Actions for automated harvesting

---

## ‚úÖ Recently Completed (January 5, 2026)

### CRITICAL: Wikidata Enrichment Cron Bug Fix (COMPLETED - Jan 5)
**Fixed critical bug causing enrichment to stall for 3 days:**
- **Issue:** Cron job query was looking for authors WITHOUT Wikidata IDs instead of those needing enrichment
- **Impact:** 100,894 authors with Wikidata IDs were stuck pending enrichment since Jan 2
- **Root Cause:** Query used `WHERE wikidata_id IS NULL` instead of `WHERE wikidata_id IS NOT NULL AND wikidata_enriched_at IS NULL`
- **Fix:** Corrected SQL query in `worker/src/routes/authors.ts:560-568`
- **Performance Boost:** Increased TARGET_AUTHORS from 1,000 to 5,000 per day
- **Timeline:** Will complete 100,844 pending authors in ~20 days (by Jan 25)
- **Optimization:** Now uses indexed query and prioritizes by `book_count DESC`
- **Verification:** Tested with 50 authors - all enriched successfully
- **Deployed:** Version `a0e6ada7-5d65-45a4-a7bc-f4535876b3f2`

**Status Before Fix:**
- Enriched: 73,533 authors
- Pending: 100,894 authors
- Last enrichment: Jan 2, 2026 (3 days ago)

**Status After Fix:**
- Enriched: 73,583 authors
- Pending: 100,844 authors
- Last enrichment: Jan 5, 2026 (working)
- Processing rate: 5,000 authors/day via cron (2 AM UTC)

### #111: Top-1000 Author Tier Harvest (COMPLETED - Jan 5)
**Completed substantial author bibliography harvest:**
- 818 authors processed (81.8% of top-1000 goal)
- 78,873 books found across processed authors
- 566 authors successfully enriched
- 566 covers queued for processing
- 475 authors failed (timeouts on very large bibliographies - expected)
- Database growth: 1,906 editions enriched in last 24h
- **Technical note:** Full 1000-author query timed out; completed top-100 tier in multiple passes
- **Future work:** Consider batch processing with smaller offsets for remaining authors
- **Checkpoint:** `data/bulk-author-checkpoint.json`

### #99: Harvesting Runbook Documentation (COMPLETED - Jan 5)
**Created comprehensive harvesting runbook with Option B approach:**
- Complete documentation in `docs/operations/HARVESTING-RUNBOOK.md`
- Three working shell scripts for automation:
  - `scripts/harvest-current-month.sh` - Monthly maintenance
  - `scripts/harvest-catchup-2025.sh` - Year backfill in quarters
  - `scripts/harvest-helper.sh` - Interactive menu for ad-hoc operations
- Documents all three harvesting strategies:
  - New releases by date range (`/api/books/enrich-new-releases`)
  - Author bibliography enrichment (`/api/authors/enrich-bibliography`)
  - Direct ISBN batch (up to 1000: `/api/enrich/batch-direct`)
- Includes quota management, monitoring, troubleshooting, and automation options
- Ready for cron automation or manual runs

### #120: Full Author Metadata in Combined Search (COMPLETED - Jan 5)
**Fixed combined search endpoint to return enriched author data:**
- Added complete author fields: `bio`, `gender`, `nationality`, `birth_year`, `death_year`, `wikidata_id`, `image`
- Fixed OpenLibrary URL construction (removed double `/authors/` prefix)
- All three query types (ISBN, author, title) now return consistent enriched metadata
- **Commit:** `2ba4e2a`
- **Deployed:** Version `19f72c71-8d62-44ea-b261-e1458618d6d2`
- **Tests:** 575/588 passing (13 integration tests skipped - require Tailscale)

**Example response:**
```json
{
  "name": "Agatha Christie",
  "openlibrary": "https://openlibrary.org/authors/OL27695A",
  "bio": "Agatha Mary Clarissa Miller was born in Torquay, Devon...",
  "gender": "female",
  "nationality": "British",
  "birth_year": 1890,
  "death_year": 1976
}
```

### Combined Search Endpoint (COMPLETED - Jan 5)
**Deployed unified search with intelligent query detection:**
- Auto-detects query type: ISBN ‚Üí Author ‚Üí Title (fallback)
- Type-specific KV caching (ISBN: 24h, Author/Title: 1h)
- Endpoint: `GET /api/search/combined?q={query}`
- Full documentation in `docs/api/API-SEARCH-ENDPOINTS.md`
- Fixed schema mismatches in enriched tables queries
- Now includes full author metadata (#120)

**Examples:**
```bash
# ISBN (auto-detected)
curl 'https://alexandria.ooheynerds.com/api/search/combined?q=9780439064873'

# Author (auto-detected)
curl 'https://alexandria.ooheynerds.com/api/search/combined?q=Stephen%20King'

# Title (fallback)
curl 'https://alexandria.ooheynerds.com/api/search/combined?q=harry%20potter'
```

---

## ‚úÖ Recently Completed (January 4, 2026)

### #90: Cross-repo Contract Testing (COMPLETED - Jan 4)
**Implemented type-safe API consumption between Alexandria ‚Üî bendv3:**
- Published `alexandria-worker@2.2.1` to npm with full type exports
- Created comprehensive test suite in bendv3: 16/19 tests passing
- Full IDE autocomplete and compile-time safety
- Documentation: `bendv3/docs/ALEXANDRIA-CONTRACT-TESTING.md`

**Benefits:**
- Breaking changes caught at compile-time
- Zero schema duplication between repos
- Automatic type inference for all endpoints

---

### #110: Wikidata Enrichment Cron Job (COMPLETED - Jan 4, FIXED - Jan 5)
**Set up automated daily Wikidata enrichment:**
- Daily cron trigger: `0 2 * * *` (2 AM UTC)
- Target: ~~1,000~~ **5,000 authors/day** (increased Jan 5)
- Parallel execution with cover harvest cron
- Worker deployed with active cron trigger

**Implementation:**
- `worker/src/routes/authors.ts`: `handleScheduledWikidataEnrichment()`
- `worker/wrangler.jsonc`: Cron trigger configuration
- ~~Queries authors without `wikidata_id`, processes in batches~~ (WRONG - Fixed Jan 5)
- **FIXED (Jan 5):** Now queries authors WITH `wikidata_id` but not yet enriched (`wikidata_enriched_at IS NULL`)
- Uses optimized index: `idx_enriched_authors_wikidata_unenriched`

**Bug Note:** Initial implementation had incorrect WHERE clause, causing 3-day stall. Fixed and deployed Jan 5.

---

### #112: VIAF/ISNI ‚Üí Wikidata Crosswalk (COMPLETED - Jan 4)
**Enabled author identification via library identifiers:**
- New endpoint: `POST /api/authors/resolve-identifier`
- Multi-strategy resolution (VIAF API ‚Üí SPARQL fallback)
- Database migration: Added `viaf_id` + `isni` columns to `enriched_authors`
- KV caching: 30-day TTL for successful resolutions
- **15/15 unit tests passing**

**Use Cases:**
- Author discovery via VIAF/ISNI from library catalogs
- Cross-reference to Wikidata for biographical enrichment
- Deduplication across identifier systems

**Documentation:** `docs/API-IDENTIFIER-RESOLUTION.md`

---

### #114: Author Deduplication (‚ö†Ô∏è PENDING DB MIGRATION)
**Implementation ready, awaiting direct database connection:**
- Migration script: `migrations/005_add_author_normalization.sql`
- Will add `normalized_name` column to `enriched_authors`
- PostgreSQL function: `normalize_author_name()` with 9 normalization rules
- 3 performance indexes (GIN trigram + B-tree)
- Auto-normalize trigger for data consistency
- Worker code ready to use normalized names

**Normalization Rules:**
- Lowercase conversion
- Whitespace trimming/collapsing
- Period spacing standardization
- Suffix removal (Jr., Sr., PhD, MD, II, III)
- Co-author extraction ("Stephen King & Owen King" ‚Üí "stephen king")
- Quote normalization
- "Various Authors" synonym handling

**Impact:**
- 25-50% faster author searches
- Better search quality (handles name variations)
- ~1-2% duplicate reduction
- Migration time: 30-60 minutes

**Documentation:** `docs/planning/AUTHOR-NORMALIZATION.md`
**Next Step:** Run migration when direct DB connection available

---

### Harvest Script Bug Fix (CRITICAL - Jan 4)
**Fixed quota check logic causing premature harvest termination:**
- Bug: Script conflated network errors with quota exhaustion
- Two occurrences: Authors 101 and 501 (false quota alerts)
- Fix: Separate `null` check (network) from `can_make_calls` check (quota)
- On network error: Log warning and CONTINUE harvest
- On actual quota exhaustion: Show detailed info and stop safely

**Impact:**
- Harvest now resilient to transient network failures
- Only stops on actual quota exhaustion with clear diagnostics
- Applied to both initial check and periodic checks

**Analysis:** `/tmp/harvest-crash-root-cause-analysis.md`
**Commit:** `aeb8fad`

---

## ‚úÖ Recently Completed (January 3, 2026)

### #109: ISBNdb Quota Tracking (COMPLETED - Jan 3)
**Fixed critical quota tracking bugs:**
- POST /api/harvest/covers wasn't tracking ISBNdb calls
- Enrichment queue handler not recording API usage
- GET /api/quota/status using wrong KV namespace

**Resolution:**
- ‚úÖ All 475 tests passing
- ‚úÖ Quota now correctly tracking all ISBNdb operations
- ‚úÖ Documentation: `docs/operations/ISBNDB-QUOTA-INVESTIGATION-JAN3.md`

### #108: Bulk Author Harvest Failures (COMPLETED - Jan 3)
**Fixed script bugs causing 17.5% failure rate:**
- Undefined variable reference (`totalAuthors`)
- Rate limiting (40 req/min vs Worker limit 10 req/min)
- ISBNdb 403 errors (now resolved)

**Resolution:**
- ‚úÖ Fixed in commit a87b6c5
- ‚úÖ Increased DELAY_MS to 6000ms (10 req/min)
- ‚úÖ Script ready for production harvests

---

## üìã TODO.md Status

### Phase 3: Performance & Search Optimization
- [x] Fix ILIKE performance, ANALYZE tables, GIN indexes
- [x] Switch search to enriched tables
- [x] Query result caching (KV), CDN headers
- [x] Verify bendv3 integration (#90)
- [ ] Add KV caching for combined search endpoint

### Phase 4: Author Enrichment Expansion
- [x] `/api/authors/enrich-bibliography` endpoint
- [x] Scripts: `expand-author-bibliographies.js`, `e2e-author-enrichment-test.js`
- [x] Run large-scale author expansion (#111 - 81.8% complete)
- [ ] Author deduplication (#114 - awaiting DB migration)

### Phase 5: Advanced Features
- [ ] Combined search (`/api/search?q={query}`)
- [ ] Pagination, export (CSV/JSON), analytics
- [ ] Semantic search with embeddings

### Phase 6: Operations
- [ ] CI/CD pipeline (GitHub Actions) - #100
- [ ] Error monitoring/alerting
- [ ] Disaster recovery plan

---

## üéØ Current Work (January 4, 2026)

### #111: Top-1000 Author Tier Harvest (IN PROGRESS)
- **Status:** 70% complete (701/1000 authors)
- **Remaining:** ~299 authors (~10 minutes)
- **Statistics:**
  - Successfully enriched: ~520 authors
  - Network errors/timeouts: ~180 authors (expected for large bibliographies)
  - Books found: ~50,000+
  - Covers queued: Hundreds
- **Bug fix applied:** Network failures no longer stop harvest

---

## üéØ Recommended Next Actions

### Immediate (When DB Access Available)
1. **Run Author Normalization Migration (#114)** - Execute `migrations/005_add_author_normalization.sql`
   - Estimated time: 30-60 minutes for 14.7M authors
   - Will add `normalized_name` column and indexes
   - Deploy updated Worker code after migration

### Short-term (This Week)
2. **Wikipedia + LLM Fallback (#113)** - For authors without Wikidata
3. **GitHub Actions Automation (#100)** - Automated harvesting pipeline

### Long-term (Next Month)
5. **Combined Search Endpoint** - Phase 5 feature
6. **Error monitoring/alerting** - Operational excellence

---

## üìä Quick Status Commands

```bash
# ISBNdb quota
curl https://alexandria.ooheynerds.com/api/quota/status | jq

# VIAF/ISNI resolution (test)
curl -X POST https://alexandria.ooheynerds.com/api/authors/resolve-identifier \
  -H 'Content-Type: application/json' \
  -d '{"type": "viaf", "id": "97113511"}'

# Worker logs
npm run tail | grep -i "cover|enrich|quota|wikidata"

# Database stats
curl https://alexandria.ooheynerds.com/api/stats | jq

# Harvest checkpoint
cat data/bulk-author-checkpoint.json | jq '.stats'

# Check normalization (after migration completes)
ssh root@Tower.local "docker exec postgres psql -U openlibrary -d openlibrary -c \
  'SELECT name, normalized_name FROM enriched_authors LIMIT 10;'"

# Check Wikidata enrichment progress
ssh root@Tower.local "docker exec postgres psql -U openlibrary -d openlibrary -c \
  'SELECT
    COUNT(*) FILTER (WHERE wikidata_id IS NOT NULL) as total_with_wikidata,
    COUNT(*) FILTER (WHERE wikidata_enriched_at IS NOT NULL) as enriched,
    COUNT(*) FILTER (WHERE wikidata_id IS NOT NULL AND wikidata_enriched_at IS NULL) as pending,
    MAX(wikidata_enriched_at) as last_enriched
  FROM enriched_authors;'"

# Test Wikidata enrichment manually (50 authors)
curl -X POST https://alexandria.ooheynerds.com/api/authors/enrich-wikidata \
  -H 'Content-Type: application/json' -d '{"limit": 50}' | jq
```

---

## üìà System Status

**Database:**
- 54.8M editions
- 14.7M authors (normalization pending migration)
- 28.6M enriched editions
- 21.2M enriched works

**Wikidata Enrichment (Jan 5, 2026):**
- Authors with Wikidata IDs: 174,427
- Enriched: 73,583 (42%)
- Pending: 100,844 (58%)
- Processing rate: 5,000/day via cron
- ETA: ~20 days (Jan 25, 2026)
- Cron bug fixed: Jan 5, 2026

**ISBNdb Quota:**
- Daily limit: 15,000 calls
- Current usage: ~2,000/15,000 (13%)
- Reset: Daily at midnight UTC

**Infrastructure:**
- Worker: Deployed (Version: a0e6ada7-5d65-45a4-a7bc-f4535876b3f2)
- Cron jobs: Active (daily 2 AM UTC) - **FIXED Jan 5**
- Tunnel: Operational (4 connections)
- Queues: Processing normally
- Tests: 575/588 passing (13 integration tests require Tailscale)

---

**Next Review:** After #111 completion (top-1000 harvest)
